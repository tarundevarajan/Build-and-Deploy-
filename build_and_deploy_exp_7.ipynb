{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "uNzqL_sgDotr",
        "outputId": "f919715e-f9bb-4faf-c592-73c2a5196095"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Part 1: Loading and Preprocessing the MNIST Dataset ---\n",
            "Normalized training data shape: (60000, 28, 28, 1)\n",
            "Example of a normalized pixel value: -1.0\n",
            "\n",
            "--- Part 2: Building the GAN Components ---\n",
            "\n",
            "--- Generator Model Summary ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Discriminator Model Summary ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Beginning GAN Training ---\n",
            "Epoch 1/2 - Generator Loss: 0.7307, Discriminator Loss: 1.0874\n",
            "Epoch 2/2 - Generator Loss: 0.7997, Discriminator Loss: 1.2802\n",
            "\n",
            "--- Training complete. Generating final images. ---\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbcAAAEfCAYAAADC2IhoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAE0pJREFUeJzt3XtolvUbx/HrmTvp3JylDVOnWR4izXSZmWamYGao4SmdkaalRIJWRGliEEUhgR2IJZGK/aEVaRh5CG2KmiaD5QEpw+nMlS4Pedjcmu77+0O2X/t5XfncOn/Oy/cLhPo8z30/9/0kfPrOy+8dCyEEAQDAkYRrfQEAANQ3yg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A6ln79u0lFotd8tfixYuv9aVGUnPd9amwsFDefvttGTRokGRlZUlSUpI0b95cHnzwQfnoo4+kqqrqss6bWK9XCQCo1bdvX7njjjvM1//ttRvBuXPnpGfPniIi0rRpU+nVq5dkZWXJoUOHZOvWrbJ582ZZsmSJrF27VjIzMyOdm3IDgKvkmWeekUmTJl3ry2jQcnJy5JVXXpHhw4dLSkpKbb5r1y555JFHZPv27fLiiy/KwoULI52XH0sCAK6JxMREKSgokDFjxtQpNhGRbt26ybx580REZNmyZZF/PEm5AUAD8c8/0/rkk08kJydH0tLSJDMzU4YOHSrbtm0zjz1+/LjMnj1b7rrrLmnSpImkp6dLTk6OzJs3T86ePWseV1JSIi+//LJ069ZN0tPTJS0tTTp16iSTJk2SH374wTzuq6++kn79+klGRoakpaVJ3759ZdWqVZd/84oePXqIiMjZs2fl6NGj0Q4OAIB61a5duyAiYdGiRZGOE5EgIuGFF14IsVgs9OvXL4wfPz507do1iEhITEwMy5cvv+i4ffv21X5my5Ytw6hRo8Lw4cNDenp6EJHQs2fPcPz48YuOW7duXcjMzAwiEm655ZYwYsSIMGbMmNCrV6+QlJQUJk6cqF7f3LlzQywWC3379g1PPPFE6N69exCREIvF1Ou7XCtWrAgiEpKTk0NFRUWkYyk3AKhnV1pujRs3DuvXr6/z2rx584KIhGbNmoUjR47Uea13795BRMLw4cPDmTNnavPS0tLQs2fPICIhNze3zjEHDx4MzZo1CyISXn311VBZWVnn9SNHjoRNmzap15eZmRm2bdtW57XXX389iEjo1KlTpHu2VFdXhz59+gQRCSNHjox8POUGAPWsptwu9evEiRN1jqvJZ86cqZ733nvvDSIS3nrrrdps06ZNQURCkyZNwuHDhy86pqCgIIhISEhICL/99lttPnPmzCAiYdiwYXHfV831ffDBBxe9VlFRUVuWBw8ejPuclpqybNq0adi7d2/k45mWBICr5FJ/FSA5OVnNJ06cqOZPPfWUFBQUyIYNG2T27NkiIrJhwwYRERkyZIhkZWVddExOTo50795dduzYIRs3bpQJEyaIiMiaNWtERGTq1Klx30+NYcOGXZSlpKRIhw4dpLCwUEpKSqRt27aRz1tjyZIl8sYbb0hCQoIsXLhQOnbsGPkclBsAXCWX+1cBbrvttn/NDx06VJuVlJT86zEiIrfffrvs2LGj9r0iIsXFxSIi0qVLl8jXl52dreYZGRkiIlJRURH5nDW+/PJLmTx5sohcGKoZM2bMZZ2HaUkAuM5c+AnhtZOQcHWqY/ny5ZKbmyvV1dWyYMGC2pK7HJQbADQw+/fvV/MDBw6IiEibNm1qs9atW4uISFFRkXm+mtdq3ivy39XXzz//fEXXWl++/vprGTdunJw/f17y8vLk2WefvaLzUW4A0MB89tln/5oPGDCgNqv55zVr1siRI0cuOqawsFB++uknSUhIkP79+9fmQ4YMEZELP/q71r755hsZO3asnDt3TvLy8mTatGlXfE7KDQAamLy8vNpBkRrz58+X7du3S3p6ukyZMqU279evn/Tu3VvOnj0r06ZNk/Ly8trXjh49WlsU48aNqzPk8eKLL0p6erqsXLlS5syZc9EOIKWlpbJ58+arcHd1rVq1SkaPHi3nzp2Tjz/+uF6KTUQkFq71D28BwJn27dtLcXHxJaclBw8eLLm5ubX/XrM7ycyZM+X999+XBx98UFq3bi27d++WXbt2SaNGjWTZsmUyevToOucpKiqSgQMHSnFxsdxyyy3Sv39/qaqqkvz8fDl16pT07NlT1q1bJ82bN69z3HfffSejR4+W06dPS1ZWlvTp00eSkpKkuLhYCgsLJTc3t86TC2quz6qNAQMGyMaNGyU/P7/O6tJSWloq2dnZUllZKW3atJFBgwaZ73333XelRYsWlzxnrSv+ywgAgDri/XtuM2bMqHNcTR5CCHl5eeGee+4JjRs3DhkZGWHIkCFhy5Yt5mceO3YszJo1K9x5550hNTU1NGnSJPTo0SO88847oby83DyuuLg4zJgxI3Tu3DmkpqaGpk2bhk6dOoXJkyeHrVu3mteneeihh4KIhPz8/Et/SSGE/fv3x/U9iUjYv39/XOeswcoNABqIS62MED/+zA0A4A7lBgBwh3IDALjD9lsA0EDwZ231h5UbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcoNwCAO5QbAMAdyg0A4A7lBgBwh3IDALhDuQEA3KHcAADuUG4AAHcS431jy5Yt1fzUqVNqXlVVpeYhhHg/8roSi8XUvL7u92qf/3phfQ/V1dX/5ysB0JCxcgMAuEO5AQDcodwAAO5QbgAAd2IhzomEpKQkNT9//rya32iDDri2+P0G4J9YuQEA3KHcAADuUG4AAHcoNwCAO5QbAMCduLffsjCldkHU7bESEvT/r4j6ffL9A8DFWLkBANyh3AAA7lBuAAB3KDcAgDuUGwDAnbinJa09JHGBNf0Yde/Nqz1dCQA3AlZuAAB3KDcAgDuUGwDAHcoNAOAO5QYAcOeK95bEBX369FHzwsLCSOcpKytT8w4dOqh5UVGRmldXV0f6XADwhJUbAMAdyg0A4A7lBgBwh3IDALhDuQEA3Il7WvJG28PQerK2tcdj8+bN1byyslLNx4wZo+ZbtmxR85SUFDW3/rskJyer+d9//63mAOAJKzcAgDuUGwDAHcoNAOAO5QYAcIdyAwC4E/e0ZFJSkppbexg2atRIzauqqtQ86pOsMzIy1Ly8vFzNp0+fruZ//PGHmj///PNqnpmZqeadO3dWc+t7i/okbmvK0frezpw5o+Zz5sxR86VLl6r5qVOn1Nxyo03VAmiYWLkBANyh3AAA7lBuAAB3KDcAgDuUGwDAnbinJa2pSCu3phytPRst1nTiyZMn1dya1uvSpYuaW9OD69evV/O5c+eqeX5+fqTrsRQUFKh5r1691Nzau9KaflywYIGap6WlqXliov5bxJp6BYCGgJUbAMAdyg0A4A7lBgBwh3IDALhDuQEA3Il7WtLawzAqa4rS2ouyrKxMzaNOXQ4cOFDNjxw5oubWdOVjjz0W6XOjat26daT3W99ndna2mkfd8/PcuXORrgcAGgJWbgAAdyg3AIA7lBsAwB3KDQDgDuUGAHAn7mlJa2rOmr6z9py0phytJ01bkpOT1fzWW29Vc2uPx3Xr1qn5c889F+n8FutzrenTVq1aRXr/gQMH1Lx///5qbu0haT1xmydrA7gesXIDALhDuQEA3KHcAADuUG4AAHcoNwCAO7EQ5zhcamqqmluHp6SkqHl5ebmaW1N81hTl1KlTI51n+vTpat68eXM1t64/6p6WUd9vsaZVrSlK63tbvXq1mk+ZMkXNo05RWlOy9cX6Pq/25wK4vrByAwC4Q7kBANyh3AAA7lBuAAB3KDcAgDtxT0ta04PWE5ytKT5rqs3aU7Ffv35qvnPnTjX/9ddf1fzs2bNqnpiob69pfS2FhYVqnpOTo+ZRFRUVqXmHDh3U3LqvH3/8Uc0ffvhhNb/55pvV/PTp02oedS/Qq409MAH8Eys3AIA7lBsAwB3KDQDgDuUGAHCHcgMAuBP3k7itJ25bU2pR8yZNmqh5fn6+mltTgtaUpvW5x44dU3PrfktLS9XcYn3u+fPn1by4uFjNs7Oz1dyaZnzppZfiuLr/OnHihJqzZyOA6xErNwCAO5QbAMAdyg0A4A7lBgBwh3IDALgT97SktZegtTejlVvTd4cPH1bzsrIyNZ88ebKa79u3L9L1HD16VM27dOmi5r169VJzi/UE7aSkJDXv0aOHmlvTm6+99pqaL1u2TM2t+2IqEoAnrNwAAO5QbgAAdyg3AIA7lBsAwB3KDQDgTtzTktZ0n7V3ovXkbmt60Hq/9bl33323mrdv317NS0pK1Nx6wrU1HXrTTTepubVXpHX91nRiRkaGmu/fv1/N58+fr+bbtm1Tc2va03pyd0MTi8Wu9SUAuA6wcgMAuEO5AQDcodwAAO5QbgAAdyg3AIA7sWCNO/6Pxo0bq3llZaWaW3shWlOF1vSj9cRtawpxz549al5RUaHm1vSmtRfl1KlT1Xzx4sVqfubMGTW3vs/77rtPzbdv367ms2bNUvPVq1er+e7du9XcmkKM87fHNXe9XCeA/w9WbgAAdyg3AIA7lBsAwB3KDQDgDuUGAHAn7r0lrWk0a8rOmoq0zvP777+ruTVtaE1pWqz3FxQUqPnx48fV/K+//or0uRbrfrOystS8vLxczXv37q3m7733XqTrYdoQgCes3AAA7lBuAAB3KDcAgDuUGwDAHcoNAOBO3NOSVVVVkU5s7S1p7eV4+vRpNbf2hHz00UfVfNOmTWpu7eW4dOlSNV+wYIGaFxcXq7ll7dq1aj5q1Cg1Hzp0qJqnpqaq+aRJk9T8zTffVPNXXnlFzQHAE1ZuAAB3KDcAgDuUGwDAHcoNAOAO5QYAcCfuJ3FbT76urq5W84QEvTetPSet81vv79Onj5q3a9dOzZ9++mk179atm5pbU50ZGRlqbj0xvEWLFpHeb+3VuWjRIjUfPHiwmlvTnp988omanzx5Us2vF+yNCeCfWLkBANyh3AAA7lBuAAB3KDcAgDuUGwDAnSuelrSmCqNq1qyZmlvTktZUobVHpfUE7T179qh527Zt1bxHjx5qXlpaquaff/65mlt7SFqfW1RUpOZdu3ZV87KyMjW3vp/rHdOSAP6JlRsAwB3KDQDgDuUGAHCHcgMAuEO5AQDciftJ3NZ0orWHpDW9ZuWZmZlqbk05WnszJibqt2Q9ybpDhw5qfujQITWfMWOGmltGjBih5n/++aeajx07Vs1TUlLU/NNPP1XzkSNHxnF1AOATKzcAgDuUGwDAHcoNAOAO5QYAcIdyAwC4E/e0pLWHpDUtaU1XWk/uPnXqlJqXl5er+bx589R81apVap6cnKzmaWlpap6Tk6PmrVq1UnPrfq09ObOzs9V8/Pjxat64cWM137x5s5p///33at63b181BwBPWLkBANyh3AAA7lBuAAB3KDcAgDuUGwDAnbinJRs1aqTm1l6R1vRg1NyaEjxx4oSa33///Wp+7NgxNc/IyFDzyspKNW/RooWaW9Ok1vdWVVWl5g888ICa//LLL2o+efJkNf/iiy/U3Lpfa1oVAK5HrNwAAO5QbgAAdyg3AIA7lBsAwB3KDQDgTixY447/w3rC9fnz5+vlQtq2bavmUaf4Tp48qebWk7ut9585c0bNH3/8cTXfuXOnmu/du1fNrT05e/fureb79u1T844dO6q59QTz+vrv1dDE+dsYwA2ClRsAwB3KDQDgDuUGAHCHcgMAuEO5AQDciXtvyas9jfbHH3+ouTXdF/V6NmzYoOYrVqxQ85UrV0b63JKSEjX/9ttv1fzdd99V84qKCjWfMGGCmlt7WnqdigSAeLByAwC4Q7kBANyh3AAA7lBuAAB3KDcAgDtxT0tWV1dfzeuIPBWZlpam5uXl5Wpu7S1pTTN+/PHHap6bm6vm1tTihx9+qObz589X8yeffFLNrWlSa29May9Q6zoBwBNWbgAAdyg3AIA7lBsAwB3KDQDgDuUGAHAn7idxJyUlqfm1mr5r1KiRmlu3k5ycHOk8sVgs0nms76Fp06Zqbj3p25pKtaZArfu90Z5MfaPdL4B/x8oNAOAO5QYAcIdyAwC4Q7kBANyh3AAA7sS9t6Q1PWjlUafXrPNYrKnCqNOSZWVlam5Nh1rvb9OmjZofOnRIzVNTU9XcehK3NdXJXpEAcDFWbgAAdyg3AIA7lBsAwB3KDQDgDuUGAHAn7r0lAQC4XrByAwC4Q7kBANyh3AAA7lBuAAB3KDcAgDuUGwDAHcoNAOAO5QYAcIdyAwC48x9wGnG9XZkgEwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import os\n",
        "\n",
        "# Suppress TensorFlow warnings for cleaner output\n",
        "tf.keras.utils.disable_interactive_logging()\n",
        "\n",
        "# --- Part 1: Dataset Loading and Preprocessing ---\n",
        "\n",
        "print(\"--- Part 1: Loading and Preprocessing the MNIST Dataset ---\")\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, _), (_, _) = mnist.load_data()\n",
        "\n",
        "# Reshape images to (28, 28, 1) and convert to float32\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')\n",
        "\n",
        "# Normalize pixel values to [-1, 1]\n",
        "x_train = (x_train - 127.5) / 127.5\n",
        "\n",
        "print(f\"Normalized training data shape: {x_train.shape}\")\n",
        "print(\"Example of a normalized pixel value:\", x_train[0, 0, 0, 0])\n",
        "\n",
        "# --- Part 2: Building the Generator and Discriminator Models ---\n",
        "\n",
        "print(\"\\n--- Part 2: Building the GAN Components ---\")\n",
        "\n",
        "latent_dim = 100  # Size of the noise vector\n",
        "\n",
        "def build_generator():\n",
        "    model = keras.Sequential(name=\"generator\")\n",
        "    # Project and reshape\n",
        "    model.add(layers.Dense(7 * 7 * 256, use_bias=False, input_shape=(latent_dim,)))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "\n",
        "    # Upsample to 7x7 -> 14x14\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Upsample to 14x14 -> 28x28\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    # Final layer: output image with tanh activation (range [-1,1])\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "\n",
        "    return model\n",
        "\n",
        "generator = build_generator()\n",
        "print(\"\\n--- Generator Model Summary ---\")\n",
        "generator.summary()\n",
        "\n",
        "def build_discriminator():\n",
        "    model = keras.Sequential(name=\"discriminator\")\n",
        "    # Downsample\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))  # Real or fake output\n",
        "\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "print(\"\\n--- Discriminator Model Summary ---\")\n",
        "discriminator.summary()\n",
        "\n",
        "# --- Part 3: Loss Functions, Optimizers, and Training ---\n",
        "\n",
        "cross_entropy = keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    return real_loss + fake_loss\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "@tf.function\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch_size, latent_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    return gen_loss, disc_loss\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model(test_input, training=False)\n",
        "    predictions_rescaled = (predictions * 0.5) + 0.5  # Scale back to [0,1]\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions_rescaled[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f\"Epoch {epoch}\", fontsize=16)\n",
        "\n",
        "    if not os.path.exists('images'):\n",
        "        os.makedirs('images')\n",
        "    plt.savefig(f'images/image_at_epoch_{epoch:04d}.png')\n",
        "    plt.show()\n",
        "\n",
        "EPOCHS = 2\n",
        "num_examples_to_generate = 1\n",
        "seed = tf.random.normal([num_examples_to_generate, latent_dim])\n",
        "\n",
        "# Prepare dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(x_train.shape[0]).batch(batch_size)\n",
        "\n",
        "def train(dataset, epochs):\n",
        "    print(\"\\n--- Beginning GAN Training ---\")\n",
        "    for epoch in range(epochs):\n",
        "        gen_loss_list = []\n",
        "        disc_loss_list = []\n",
        "\n",
        "        for image_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch)\n",
        "            gen_loss_list.append(gen_loss.numpy())\n",
        "            disc_loss_list.append(disc_loss.numpy())\n",
        "\n",
        "        avg_gen_loss = np.mean(gen_loss_list)\n",
        "        avg_disc_loss = np.mean(disc_loss_list)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs} - \"\n",
        "              f\"Generator Loss: {avg_gen_loss:.4f}, \"\n",
        "              f\"Discriminator Loss: {avg_disc_loss:.4f}\")\n",
        "\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            generate_and_save_images(generator, epoch + 1, seed)\n",
        "\n",
        "    print(\"\\n--- Training complete. Generating final images. ---\")\n",
        "    generate_and_save_images(generator, epochs, seed)\n",
        "\n",
        "# Run training\n",
        "train(train_dataset, EPOCHS)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M5zOjezUQj7d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}